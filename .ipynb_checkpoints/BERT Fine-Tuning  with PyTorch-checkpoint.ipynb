{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a77bafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9da5959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56904c4b",
   "metadata": {},
   "source": [
    "# CoLA Dataset\n",
    " The Corpus of Linguistic Acceptability (CoLA) dataset for single sentence classification is used. It’s a set of sentences labeled as grammatically correct or incorrect. <br>\n",
    " \n",
    " The dataset is hosted on GitHub in this repo: https://nyu-mll.github.io/CoLA/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a520b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a5660a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "print('Downloading dataset...')\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "if not os.path.exists('./cola_public_1.1.zip'):\n",
    "    wget.download(url, './cola_public_1.1.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580ab02",
   "metadata": {},
   "source": [
    "Unzipping the dataset to the file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51bf3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./cola_public/'):\n",
    "    !unzip cola_public_1.1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5120aee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angela characterized Shelly as a lifesaver.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They're not finding it a stress being in the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>l-93</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Paul exhaled on Mary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>c_13</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>I ordered if John drink his beer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>bc01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Press the stamp against the pad completely.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>ks08</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>They can very.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6915</th>\n",
       "      <td>m_02</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This arch is supporting the weight of the tower.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>That new handle detaches easily.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>c_13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Brazilians pumped the oil across the river.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is a wooden desk.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  label label_notes   \n",
       "2389            l-93      1         NaN  \\\n",
       "5048            ks08      1         NaN   \n",
       "3133            l-93      0           *   \n",
       "5955            c_13      0           *   \n",
       "625             bc01      1         NaN   \n",
       "3542            ks08      0           *   \n",
       "6915            m_02      1         NaN   \n",
       "2908            l-93      1         NaN   \n",
       "5857            c_13      1         NaN   \n",
       "4191            ks08      1         NaN   \n",
       "\n",
       "                                               sentence  \n",
       "2389        Angela characterized Shelly as a lifesaver.  \n",
       "5048  They're not finding it a stress being in the s...  \n",
       "3133                              Paul exhaled on Mary.  \n",
       "5955                  I ordered if John drink his beer.  \n",
       "625         Press the stamp against the pad completely.  \n",
       "3542                                     They can very.  \n",
       "6915   This arch is supporting the weight of the tower.  \n",
       "2908                   That new handle detaches easily.  \n",
       "5857    The Brazilians pumped the oil across the river.  \n",
       "4191                               It is a wooden desk.  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97e0d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 8,551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b6864",
   "metadata": {},
   "source": [
    "<font size=\"3\">The two properties we actually care about are the the sentence and its label, which is referred to as the “acceptibility judgment” (0=unacceptable, 1=acceptable). <br><font size=\"3\">\n",
    "\n",
    "<font size=\"3\">Here are five sentences which are labeled as not grammatically acceptible:<font size=\"3\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef26792a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>We realised that Dr Jones died because he ate ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Here's a pole for you to kiss the girl who tie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>Jennifer baked at the potatoes.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>Kim is resembled by the model in nearly every ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>The book sent to Peter.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label\n",
       "6770  We realised that Dr Jones died because he ate ...      0\n",
       "1652  Here's a pole for you to kiss the girl who tie...      0\n",
       "3258                    Jennifer baked at the potatoes.      0\n",
       "4651  Kim is resembled by the model in nearly every ...      0\n",
       "2672                            The book sent to Peter.      0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label == 0].sample(5)[['sentence', 'label']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbe94c",
   "metadata": {},
   "source": [
    "<font size=\"3\">Extracting the sentences and labels of our training set as numpy ndarrays:<font size=\"3\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab8cc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701677d4",
   "metadata": {},
   "source": [
    "# Tokenization and Input Formatting\n",
    "\n",
    "<font size=\"3\">Our dataset is transformed into the format that BERT can be trained on.<font size=\"3\">\n",
    "\n",
    "\n",
    "## BERT Tokenizer\n",
    "\n",
    "<font size=\"3\">The text should be splitted into tokens to be fed into BERT, and the the tokens must be mapped to their index in the tokenizer vocabulary. The tokenization is performed by the  tokenizer included with BERT<font size=\"3\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f12b1a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eb6d5",
   "metadata": {},
   "source": [
    "<font size=\"3\">As an example, the tokenizer is applied to one sentence here:<font size=\"3\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8a06e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
      "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', sentences[0])\n",
    "\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c7768",
   "metadata": {},
   "source": [
    "<font size=\"3\"> The <font color='red'> tokenize.encode </font> function is used to implement both steps of tokenizing and mapping to the token ids. Before, tokenization we need to follow the following steps:<br>\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "1. Pad and truncate all sentences to a single constant length.\n",
    "1. Explicitly differentiate real tokens from padding tokens with   the “attention mask”.\n",
    "    \n",
    "    \n",
    "<font size=\"4\">**[SEP]**<font size=\"4\">\n",
    "\n",
    "At the end of every sentence, we need to append the special [SEP] token.\n",
    "\n",
    "This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (e.g., can the answer to the question in sentence A be found in sentence B?).\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"4\">**[CLS]**<font size=\"4\">\n",
    "\n",
    "For classification tasks, we must append the special [CLS] token to the beginning of every sentence.\n",
    "\n",
    "This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output.\n",
    "    \n",
    "    \n",
    "On the output of the final (12th) transformer, only the first embedding (corresponding to the [CLS] token) is used by the classifier.\n",
    "\n",
    "“The first token of every sequence is always a special classification token ([CLS]). The final hidden state corresponding to this token is used as the aggregate sequence representation for classification tasks.” \n",
    "    \n",
    "    \n",
    "* All sentences must be padded or truncated to a single, fixed length.\n",
    "* The maximum sentence length is 512 tokens.\n",
    "    \n",
    "Furthermore, the “Attention Mask” is  an array of 1s and 0s indicating which tokens are padding and which aren’t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8106eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  47\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867b527",
   "metadata": {},
   "source": [
    "Now the following steps are done through **tokenizer.encode_plus**:\n",
    "1. Split the sentence into tokens.\n",
    "1. Add the special [CLS] and [SEP] tokens.\n",
    "1. Map the tokens to their IDs.\n",
    "1. Pad the sentences to the same length.\n",
    "1. Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2165d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/setareh/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
      "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde9f6ae",
   "metadata": {},
   "source": [
    "# Training and Validation split\n",
    "\n",
    "We divide the training set to use 90% for training and 10% for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af9ac6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7695 training samples\n",
      "856 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "#To create Torch Dataset just pass your input and labels in the \n",
    "#TensorDataset class and it will give you all your data samples\n",
    "#in torch tensor form. \n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "#DataLoader class arranged your dataset class into small batches. \n",
    "# the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{} training samples'.format(train_size))\n",
    "print('{} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b068a12",
   "metadata": {},
   "source": [
    "The torch DataLoader class is used that helps saving memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dcc6e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706d811",
   "metadata": {},
   "source": [
    "# Train Our Classification Model\n",
    "\n",
    "* First, we want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset <br><br>\n",
    "\n",
    "* The **huggingface** pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Even though each of the interfaces has different top layers and output types designed to accomodate their specific NLP tasks, they are all built on top of a trained BERT model. The following are the classses provided for fine-tuning: <br>\n",
    "    1. BertModel\n",
    "    1. **BertForSequenceClassification** - The one we’ll use.\n",
    "    1. BertForPreTraining\n",
    "    1. BertForMaskedLM\n",
    "    1. BertForNextSentencePrediction\n",
    "    1. BertForTokenClassification\n",
    "    1. BertForQuestionAnswering\n",
    "    \n",
    "The **BertForSequenceClassification** is just a normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "833627d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "    return_dict=False\n",
    "    )\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea318e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aaeab1",
   "metadata": {},
   "source": [
    "## Optimizer and Learning Rate Scheduler\n",
    "\n",
    "According to the BERT paper, it is recommended to choose from the following values for the purposes of fine-tuning:<br>\n",
    "* Batch size: 16, 32\n",
    "* Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
    "* Number of epochs: 2, 3, 4\n",
    "\n",
    "The parameters that are chose here:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "501775e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/setareh/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#AdamW is a class from the huggingface library\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 3e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6125cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47fab54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6fbf4b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    481.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    481.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    481.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    481.    Elapsed: 0:00:10.\n",
      "  Batch   200  of    481.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    481.    Elapsed: 0:00:15.\n",
      "  Batch   280  of    481.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    481.    Elapsed: 0:00:20.\n",
      "  Batch   360  of    481.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    481.    Elapsed: 0:00:25.\n",
      "  Batch   440  of    481.    Elapsed: 0:00:28.\n",
      "  Batch   480  of    481.    Elapsed: 0:00:30.\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:31\n",
      "  Accuracy: 0.01\n",
      "  Validation took: 0:00:01\n",
      "  Validation Loss: 0.02\n",
      "\n",
      "======== Epoch 2 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    481.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    481.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    481.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    481.    Elapsed: 0:00:10.\n",
      "  Batch   200  of    481.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    481.    Elapsed: 0:00:15.\n",
      "  Batch   280  of    481.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    481.    Elapsed: 0:00:20.\n",
      "  Batch   360  of    481.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    481.    Elapsed: 0:00:25.\n",
      "  Batch   440  of    481.    Elapsed: 0:00:28.\n",
      "  Batch   480  of    481.    Elapsed: 0:00:30.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:31\n",
      "  Accuracy: 0.02\n",
      "  Validation took: 0:00:01\n",
      "  Validation Loss: 0.01\n",
      "\n",
      "======== Epoch 3 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    481.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    481.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    481.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    481.    Elapsed: 0:00:11.\n",
      "  Batch   200  of    481.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    481.    Elapsed: 0:00:16.\n",
      "  Batch   280  of    481.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    481.    Elapsed: 0:00:21.\n",
      "  Batch   360  of    481.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    481.    Elapsed: 0:00:26.\n",
      "  Batch   440  of    481.    Elapsed: 0:00:29.\n",
      "  Batch   480  of    481.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:31\n",
      "  Accuracy: 0.02\n",
      "  Validation took: 0:00:01\n",
      "  Validation Loss: 0.01\n",
      "\n",
      "======== Epoch 4 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    481.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    481.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    481.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    481.    Elapsed: 0:00:10.\n",
      "  Batch   200  of    481.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    481.    Elapsed: 0:00:15.\n",
      "  Batch   280  of    481.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    481.    Elapsed: 0:00:21.\n",
      "  Batch   360  of    481.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    481.    Elapsed: 0:00:26.\n",
      "  Batch   440  of    481.    Elapsed: 0:00:28.\n",
      "  Batch   480  of    481.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:31\n",
      "  Accuracy: 0.01\n",
      "  Validation took: 0:00:01\n",
      "  Validation Loss: 0.03\n",
      "\n",
      "======== Epoch 5 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    481.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    481.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    481.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    481.    Elapsed: 0:00:10.\n",
      "  Batch   200  of    481.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    481.    Elapsed: 0:00:16.\n",
      "  Batch   280  of    481.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    481.    Elapsed: 0:00:21.\n",
      "  Batch   360  of    481.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    481.    Elapsed: 0:00:26.\n",
      "  Batch   440  of    481.    Elapsed: 0:00:28.\n",
      "  Batch   480  of    481.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:31\n",
      "  Accuracy: 0.02\n",
      "  Validation took: 0:00:01\n",
      "  Validation Loss: 0.01\n",
      "\n",
      "======== Epoch 6 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    481.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    481.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    481.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    481.    Elapsed: 0:00:10.\n",
      "  Batch   200  of    481.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    481.    Elapsed: 0:00:15.\n",
      "  Batch   280  of    481.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    481.    Elapsed: 0:00:21.\n",
      "  Batch   360  of    481.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    481.    Elapsed: 0:00:26.\n",
      "  Batch   440  of    481.    Elapsed: 0:00:28.\n",
      "  Batch   480  of    481.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:31\n",
      "  Accuracy: 0.02\n",
      "  Validation took: 0:00:01\n",
      "  Validation Loss: 0.01\n",
      "\n",
      "======== Epoch 7 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    481.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    481.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    481.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    481.    Elapsed: 0:00:10.\n",
      "  Batch   200  of    481.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    481.    Elapsed: 0:00:15.\n",
      "  Batch   280  of    481.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    481.    Elapsed: 0:00:20.\n",
      "  Batch   360  of    481.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    481.    Elapsed: 0:00:25.\n",
      "  Batch   440  of    481.    Elapsed: 0:00:28.\n",
      "  Batch   480  of    481.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:31\n",
      "  Accuracy: 0.01\n",
      "  Validation took: 0:00:01\n",
      "  Validation Loss: 0.02\n",
      "\n",
      "======== Epoch 8 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    481.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    481.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    481.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    481.    Elapsed: 0:00:10.\n",
      "  Batch   200  of    481.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    481.    Elapsed: 0:00:15.\n",
      "  Batch   280  of    481.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    481.    Elapsed: 0:00:20.\n",
      "  Batch   360  of    481.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    481.    Elapsed: 0:00:25.\n",
      "  Batch   440  of    481.    Elapsed: 0:00:28.\n",
      "  Batch   480  of    481.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:31\n",
      "  Accuracy: 0.02\n",
      "  Validation took: 0:00:01\n",
      "  Validation Loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "epochs = 8\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#storing the training and validation loss and accuracy:\n",
    "training_stats = {'epoch': [],'Training Loss': [],'Valid. Loss': [],\n",
    "            'Valid. Accur.': [],\n",
    "            'Training Time': [],\n",
    "            'Validation Time': []}\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    #Activate the model into training mode. \n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        \n",
    "        \n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Always clear any previously calculated gradients before backward pass\n",
    "        model.zero_grad()    \n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        #`loss` is a Tensor containing a single value; \n",
    "        #the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        #Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)  \n",
    "    \n",
    "    \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    \n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))      \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    t0 = time.time()      \n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "          \n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "          \n",
    "    for batch in validation_dataloader:\n",
    "          \n",
    "          b_input_ids = batch[0].to(device)\n",
    "          b_input_mask = batch[1].to(device)\n",
    "          b_labels = batch[2].to(device)\n",
    "          \n",
    "          #Not compute the graph during the forward pass, since this is\n",
    "          #only needed for backprop (training).\n",
    "          with torch.no_grad(): \n",
    "              (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "          \n",
    "    # Accumulate the validation loss.\n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "          \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "     # Record all statistics from this epoch.\n",
    "    training_stats['epoch'].append(epoch_i + 1)\n",
    "    training_stats['Training Loss'].append(avg_train_loss)\n",
    "    training_stats['Valid. Loss'].append(avg_val_loss)\n",
    "    training_stats['Valid. Accur.'].append(avg_val_accuracy)\n",
    "    training_stats['Training Time'].append(training_time)\n",
    "    training_stats['Validation Time'].append(validation_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9a4fffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'Training Loss': [0.1039415763939388,\n",
       "  0.07985301887653545,\n",
       "  0.07725108335173535,\n",
       "  0.06719671030440019,\n",
       "  0.08448524082458544,\n",
       "  0.08183192444581387,\n",
       "  0.06904210334945288,\n",
       "  0.09238073843015307],\n",
       " 'Valid. Loss': [0.02015800608528985,\n",
       "  0.013650674510885167,\n",
       "  0.011288935387576068,\n",
       "  0.02510399509359289,\n",
       "  0.01180672424810904,\n",
       "  0.010833442211151123,\n",
       "  0.024644213694113272,\n",
       "  0.011673182249069214],\n",
       " 'Valid. Accur.': [0.013888888888888888,\n",
       "  0.016203703703703703,\n",
       "  0.016203703703703703,\n",
       "  0.013888888888888888,\n",
       "  0.016203703703703703,\n",
       "  0.016203703703703703,\n",
       "  0.013888888888888888,\n",
       "  0.016203703703703703],\n",
       " 'Training Time': ['0:00:31',\n",
       "  '0:00:31',\n",
       "  '0:00:31',\n",
       "  '0:00:31',\n",
       "  '0:00:31',\n",
       "  '0:00:31',\n",
       "  '0:00:31',\n",
       "  '0:00:31'],\n",
       " 'Validation Time': ['0:00:01',\n",
       "  '0:00:01',\n",
       "  '0:00:01',\n",
       "  '0:00:01',\n",
       "  '0:00:01',\n",
       "  '0:00:01',\n",
       "  '0:00:01',\n",
       "  '0:00:01']}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3e6885b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stats[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e6b62c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103942</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0:00:31</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079853</td>\n",
       "      <td>0.013651</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>0:00:31</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077251</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>0:00:31</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067197</td>\n",
       "      <td>0.025104</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0:00:31</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.084485</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>0:00:31</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.081832</td>\n",
       "      <td>0.010833</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>0:00:31</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.069042</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0:00:31</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.092381</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>0:00:31</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1           0.103942     0.020158       0.013889       0:00:31         0:00:01\n",
       "2           0.079853     0.013651       0.016204       0:00:31         0:00:01\n",
       "3           0.077251     0.011289       0.016204       0:00:31         0:00:01\n",
       "4           0.067197     0.025104       0.013889       0:00:31         0:00:01\n",
       "5           0.084485     0.011807       0.016204       0:00:31         0:00:01\n",
       "6           0.081832     0.010833       0.016204       0:00:31         0:00:01\n",
       "7           0.069042     0.024644       0.013889       0:00:31         0:00:01\n",
       "8           0.092381     0.011673       0.016204       0:00:31         0:00:01"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05a34d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e635a435",
   "metadata": {},
   "source": [
    "# Performance On Test Set\n",
    "\n",
    "\n",
    "Now we load the holdout dataset and then evaluate the predictions using \" Matthew’s correlation coefficient\". Matthew's correlation coefficient (MCC) is a measure of the quality of binary classification predictions. It takes into account true positives, true negatives, false positives, and false negatives to evaluate the performance of a binary classification model. MCC ranges from -1 to 1, where 1 indicates a perfect prediction, 0 indicates a random prediction, and -1 indicates a total disagreement between the prediction and the ground truth.\n",
    "\n",
    "MCC = (TP * TN - FP * FN) / sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5d9e8",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba4d5f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 516\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/setareh/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e631f",
   "metadata": {},
   "source": [
    "# Evaluate on Test Set\n",
    "\n",
    "We apply our fine-tuned model to generate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06b302a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 516 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                  attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64f6186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use MCC here because the classes are imbalanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "96834736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 354 of 516 (68.60%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fa6137a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6fea2",
   "metadata": {},
   "source": [
    "MCC ranges from -1 to 1, where 1 indicates a perfect prediction, 0 indicates a random prediction, and -1 indicates a total disagreement between the prediction and the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43efce52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
